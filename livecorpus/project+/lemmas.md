# предобработка
1. Я выгрузила слой "words@aom2003f" в формате tsv
2. с помощью регулярных выражений я хочу сделать из него файл csv (потому что я хочу в своей работе использовать модуль pandas, так как хорошо понимаю, как с ним работать). Я заранее знаю, что в файле очень много запятых, которые будут мешать файлу читаться как надо(запятые будут читаться как лишние столбцы). Поэтому я все запятые заменю на '~', потому что этот символ не помешает мне работать с файлом и таких символов у меня в разметке точно нет, следовательно в итоге ничего важного я не изменю. 
3. сделала из него файл csv (найти: "\t" заменить: "," ,без кавычек естественно)
4. затем я через запятую написала названия для наших столбцов ('layer', 'speaker', и т.д.)

# питон и pymystem3 
### перечисляю, что я делала
1. я импортировала все нужные модули и библиотеки
2. я прочитала мой csv файл с words
3. я написала две очень похожих функции, lemmas и morphs. Lemmas работает так:
	1. я создаю csv файл, куда буду записывать новый слой для импорта и открываю его для записи
	2. я с помощью цикла прохожусь по всем словам (столбик "wordie"). Каждое из слов записываю в новую переменную и лемматизирую. Поскольку опытным путем было выявлено, что функция Mystem 'lemmatize()' выдает структуру данных list, первый элемент которого - собственно нужная нам лемма, то я присваиваю переменной lemma новое значение - lemma\[0\]. 
	3.  Потом, записываю в новый файл строку, состоящую из всей нужной мне информации 
4. Morphs работает так:
	1. 1. я создаю csv файл, куда буду записывать новый слой для импорта и открываю его для записи
	2. я с помощью цикла прохожусь по всем словам (столбик "wordie"). Каждое из слов записываю в новую переменную и анализирую. Поскольку опытным путем было выявлено, что функция Mystem 'analyze()' выдает самую запутанную структуру данных, которую только может (сложно организованная пирамида из списков и словарей, причем иногда она отличается), я делаю еще один цикл, где проверяю, каким именно образом mystem решил проанализировать мое слово. Мне нужны значения из ключа "gr", беру их, если они есть. Уже на этом этапе замечаю, что mystem разбивает символы отдельно от букв, а ELAN так не умеет, поэтому все знаки препинания не анализируются и веши типа "{СМЕХ}" не анализируются, а просто выдаются как текст
	3.  Потом, записываю в новый файл строку, состоящую из всей нужной мне информации 
## Подготовка к загрузке в ELAN и загрузка
1. регулярными выражениями я открываю каждый файл и делаю(" " = пробел):
	1. найти:" " заменить: \t (у меня так сформировался из-за скрипта)
	2.  найти:\n\n заменить: \n
	3.  найти: \\| заменить: " "
	4. найти: \x{0D} заменить " "
	5.  найти:~ заменить: , (помним о том, что мы делали в начале)
	6. также по мелочи что не так
2. затем я загрузила слои, выбрала нужные столбцы, настроила все в слоях (тип слоя указать не удалось)
## Проблемы 
основная проблема: разница методов токенизации Элана и Майстем, точнее токенизация небуквенных символов. К примеру, при автоматическом анализе от "{СМЕХ}" остается только "{". Также, как уже было описано мной выше, Майстем не может анализировать символы, иностранные слова, "эээ" и тп. (по той же манере, по которой он анализирует обычные слова)
